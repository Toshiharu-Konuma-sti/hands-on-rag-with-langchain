{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4754a68c-64f2-48f7-a357-87819daafcd2",
   "metadata": {},
   "source": [
    "# Step 5: Web UI (Chatting with Open LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c926d6-2719-41e5-840e-69d65e5c6d16",
   "metadata": {},
   "source": [
    "本ステップでは、Step 2以降で経験してきたナレッジを活用して簡易的なRAGアプリケーションの構築を経験します。\n",
    "- Step 2以降で準備したRetrieverとGeneratorを使ってRAGの実装を用意する\n",
    "- RAGの実装を活用しやすいように、Gradioを用いてFront-endになるWeb UIを実装する\n",
    "- Web UIから質問を投げかけてRAGを体験する\n",
    "![Step5](../image/rag-overview-step5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a71b66-4df0-4b73-9fee-8b1d7ecafe19",
   "metadata": {},
   "source": [
    "## 0. 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4df55-049e-4687-9376-fadf71259fcd",
   "metadata": {},
   "source": [
    "### 共通処理/定数定義\n",
    "全ステップで共通して使用する定数とバナークラスを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2cfeca-b057-4354-a79a-b956182465e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mylib import myconstant\n",
    "from mylib.MyBanner import MyBanner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fceee8e-da84-4570-a8d8-e41d5412984d",
   "metadata": {},
   "source": [
    "### Access Token入力\n",
    "Open LLMの取得に必要となるHugging FaceのAccess Tokenを入力します。（事前に発行して入手しておきます）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b2600-1ad0-4ce6-bdbc-27a95ce003c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyBanner.start()\n",
    "\n",
    "from getpass import getpass\n",
    "HF_ACCESS_TOKEN = getpass(\"Hugging Face の Access Token を入力して Enter Key を押してください: \")\n",
    "\n",
    "MyBanner.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61c71e-7d2b-4366-a8c2-0116d1d2f104",
   "metadata": {},
   "source": [
    "### パッケージインストール\n",
    "本ステップの処理で依存するパッケージをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d666a-41a7-44c6-a02f-7ab192584838",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyBanner.start()\n",
    "\n",
    "!python -V\n",
    "!pip install langchain\n",
    "!pip install langchain-huggingface\n",
    "!pip install langchain_milvus\n",
    "!pip install accelerate\n",
    "!pip install --upgrade gradio\n",
    "\n",
    "!pip install ipywidgets\n",
    "!pip install urllib3==1.26.20\n",
    "\n",
    "MyBanner.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb0f83a-9f73-4216-a6a6-f34389a7d44e",
   "metadata": {},
   "source": [
    "### import\n",
    "本ステップの処理で依存するモジュールを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cab076-e79c-4337-991d-1c5a10107624",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyBanner.start()\n",
    "\n",
    "from mylib.MyEmbedding import MyEmbedding\n",
    "from mylib.MyMilvus import MyMilvus\n",
    "from mylib.MyOpenLlmList import MyOpenLlmList\n",
    "from mylib.MyGenerator import MyGenerator\n",
    "import gradio as gr\n",
    "\n",
    "MyBanner.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aae473-7985-44cd-8d16-a5add779797a",
   "metadata": {},
   "source": [
    "## 1. 生成: VectorDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4ffd4-9b64-4b7e-a333-5bbd810790a5",
   "metadata": {},
   "source": [
    "### 【準備】Embedding Model読込\n",
    "Embedding Modelをメモリに読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59378ea2-6ba3-4245-8969-2a0ef5fc5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyBanner.start()\n",
    "\n",
    "embeddings = MyEmbedding.get_model()\n",
    "display(embeddings)\n",
    "\n",
    "MyBanner.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd14ba89-306e-4bf4-99b7-deac717eea65",
   "metadata": {},
   "source": [
    "### 【準備】Vector DB接続\n",
    "エンベディングで利用するEmbedding Modelと接続情報を渡してベクトルデータベースへ接続します。\n",
    "- 接続失敗した場合は、Milvus(milvus-standalone コンテナ)が起動しているか確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b4d76-62db-4fd8-a849-01367414ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyBanner.start()\n",
    "\n",
    "# connect to VectorDB\n",
    "vector_db = MyMilvus(\n",
    "    myconstant.VDB_HOST, myconstant.VDB_PORT,\n",
    "    myconstant.VDB_USER, myconstant.VDB_PASS, embeddings)\n",
    "print(f\"{vector_db=}\")\n",
    "\n",
    "MyBanner.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4823a1a6-e022-4267-9766-e3fd672951bd",
   "metadata": {},
   "source": [
    "## 2. 生成: Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a000d633-50e2-460b-9807-0e1dbf97c825",
   "metadata": {},
   "source": [
    "### 【生成】Open LLM一覧\n",
    "取り扱うOpen LLM名の一覧を管理するオブジェクトを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f0a08-b486-4b56-a6cd-0c775a761040",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyBanner.start()\n",
    "\n",
    "openllm_list = MyOpenLlmList([2, 4])\n",
    "\n",
    "MyBanner.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc692aec-7134-41cd-80cd-cc4cd3de1779",
   "metadata": {},
   "source": [
    "### 【生成】Generator Object\n",
    "プロンプトを使ってLLMへ回答案の作成依頼を連携するGeneratorオプジェクトを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912136d-1aeb-4f96-bd53-a5332cbb210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyBanner.start()\n",
    "\n",
    "generator = MyGenerator(openllm_list.getAll(), HF_ACCESS_TOKEN)\n",
    "display(generator)\n",
    "\n",
    "MyBanner.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302becbb-8d1c-48db-99ee-38f78e5773a3",
   "metadata": {},
   "source": [
    "## 3. Web UI to chat with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d0669-9992-42fa-8922-fe2f42ad1b0d",
   "metadata": {},
   "source": [
    "### Script for Web UI written in Gradio\n",
    "- Components manual in Gradio: https://www.gradio.app/docs/gradio/interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fb1259-86cb-43b8-8200-18c50daf77c8",
   "metadata": {},
   "source": [
    "以下の画面で構成されるWeb UIを使ってRAGを体験します。\n",
    "\n",
    "| ![Step5](../image/chatting_with_openllm.png) |\n",
    "|:---:|\n",
    "| 図. Web UIの画面構成 |\n",
    "\n",
    "次のセルはWeb UIを構築するソースコードで、実行後にソースコードのセル直下に表示されるURLでWeb UIにアクセスします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37903924-48e4-4fc7-ab48-6db69e974c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------------------------------------------\n",
    "# define global variables\n",
    "#--------------------------------------------------\n",
    "gbal_response = None\n",
    "gbal_collections = vector_db.get_collections()\n",
    "print(f\"{gbal_collections=}\")\n",
    "\n",
    "#--------------------------------------------------\n",
    "# define event procedures and sub functions\n",
    "#--------------------------------------------------\n",
    "\n",
    "def create_chain(drp_llm, is_conversation, \n",
    "                 is_retrieval, drp_collection,\n",
    "                 is_apply_cond, nmb_rec, sld_sim, \n",
    "                 is_edit_template, txt_template):\n",
    "\n",
    "    # decide a template for prompt\n",
    "    template = None\n",
    "    if is_edit_template == \"On\":\n",
    "        template = txt_template\n",
    "    elif (not gbal_response is None) and (is_conversation == \"On\"):\n",
    "        template = generator.make_template_for_conversation(drp_llm, gbal_response)\n",
    "    # create a chain    \n",
    "    if is_retrieval == \"On\":\n",
    "        docstore = vector_db.connect(drp_collection)\n",
    "        if is_apply_cond == \"On\":\n",
    "            retriever = vector_db.get_retriever(docstore, nmb_rec, sld_sim)\n",
    "        else:\n",
    "            retriever = vector_db.get_retriever(docstore)\n",
    "        chain = generator.create_chain(retriever, drp_llm, template)\n",
    "    else:\n",
    "        chain = generator.create_chain_not_retriever(drp_llm, template)\n",
    "    return chain\n",
    "\n",
    "def chatbot_response(message, history, \n",
    "                     drp_llm, is_conversation,\n",
    "                     is_retrieval, drp_collection,\n",
    "                     is_apply_cond, nmb_rec, sld_sim,\n",
    "                     is_edit_template, txt_template):\n",
    "    MyBanner.start()\n",
    "    global gbal_response\n",
    "    \n",
    "    print(f\"{message=}\",\n",
    "          f\"{drp_llm=}\", f\"{is_conversation=}\",\n",
    "          f\"{is_retrieval=}\", f\"{drp_collection=}\",\n",
    "          f\"{is_apply_cond=}\", f\"{nmb_rec=}\", f\"{sld_sim=}\")\n",
    "\n",
    "    # Create a chain\n",
    "    chain = create_chain(drp_llm, is_conversation, \n",
    "                         is_retrieval, drp_collection,\n",
    "                         is_apply_cond, nmb_rec, sld_sim, \n",
    "                         is_edit_template, txt_template)\n",
    "    \n",
    "    response = chain.invoke(message)\n",
    "    gbal_response = response\n",
    "    print(f\"{response=}\" + \"\\n\" + (\"-\" * 30))\n",
    "    \n",
    "    answer = generator.extract_answer_from_response(drp_llm, response)\n",
    "    print(f\"{answer=}\" + \"\\n\" + (\"-\" * 30))\n",
    "    \n",
    "    MyBanner.finish()\n",
    "    print()\n",
    "    return answer\n",
    "\n",
    "def change_radio_similarity(sld_sim):\n",
    "    print(sld_sim)\n",
    "    return sld_sim\n",
    "\n",
    "def change_dropdown_llm():\n",
    "    return gr.update(value=\"Off\"), gr.update(value=\"\", visible=False)\n",
    "\n",
    "def change_radio_retrieval(is_retrieval):\n",
    "    if is_retrieval == \"On\":\n",
    "        return gr.update(visible=True)\n",
    "    else:\n",
    "        return gr.update(visible=False)\n",
    "\n",
    "def change_radio_apply_cond(is_apply_cond):\n",
    "    flg_visible = False\n",
    "    if is_apply_cond == \"On\":\n",
    "        flg_visible = True\n",
    "    return gr.update(visible=flg_visible), gr.update(visible=flg_visible)\n",
    "\n",
    "def change_radio_edit_template(is_edit_template, txt_template, drp_llm):\n",
    "    if is_edit_template == \"On\":\n",
    "        template = txt_template\n",
    "        if template.strip() == \"\":\n",
    "            template = generator.get_template(drp_llm)\n",
    "        return gr.update(visible=True, value=template)\n",
    "    else:\n",
    "        return gr.update(visible=False)\n",
    "\n",
    "#--------------------------------------------------\n",
    "# draw a gui\n",
    "#--------------------------------------------------\n",
    "# with gr.Blocks(fill_height=True, theme=gr.themes.Citrus()) as demo:\n",
    "with gr.Blocks(fill_height=True) as demo:\n",
    "    gr.Markdown(\"## Chatting with Open LLM (App for understanding RAG mechanism)\")\n",
    "    with gr.Accordion(\"Use conditions:\", open=True):\n",
    "        with gr.Tab(\"Basic Conditions\"):\n",
    "            with gr.Row():\n",
    "                drp_llm = gr.Dropdown(openllm_list.getAll(),\n",
    "                                      label=\"Open LLM:\",\n",
    "                                      info=\"Select a LLM to generate an answer.\",\n",
    "                                      value=openllm_list.get(0), interactive = True, visible=True)\n",
    "                is_conversation = gr.Radio(choices=[\"On\", \"Off\"], type=\"value\",\n",
    "                                           label=\"Conversation:\",\n",
    "                                           info=\"Respond with a continuous conversation..\",\n",
    "                                           value=\"Off\", interactive=True)\n",
    "                is_retrieval = gr.Radio(choices=[\"On\", \"Off\"], type=\"value\",\n",
    "                                        label=\"Retriever(Similarity vector search):\",\n",
    "                                        info=\"Provide with data for similarity search to answer.\",\n",
    "                                        value=\"On\", interactive=True)\n",
    "                drp_collection = gr.Dropdown(gbal_collections,\n",
    "                                             label=\"Collection:\",\n",
    "                                             info=\"Select a collection for similarity search.\",\n",
    "                                             value=gbal_collections[0],\n",
    "                                             interactive = True, visible=True)\n",
    "        with gr.Tab(\"Retriever Condition\") as tab_retriever:\n",
    "            with gr.Row():\n",
    "                is_apply_cond = gr.Radio(choices=[\"On\", \"Off\"], type=\"value\", value=\"Off\", \n",
    "                                         label=\"Detail conditions for retriever:\",\n",
    "                                         info=\"Choose a mode to adjust using the conditions on the right. If this feature is enabled, there will be no continuous conversation.\",\n",
    "                                         interactive=True)\n",
    "                nmb_rec = gr.Number(value=15,\n",
    "                                    label=\"1. Number of records:\",\n",
    "                                    info=\"Input a value as 'k' of similarity_search().\",\n",
    "                                    visible=False, interactive=True)\n",
    "                sld_sim = gr.Slider(minimum=0.6, maximum=1.0, step=0.01, value=0.7,\\\n",
    "                                    label=\"2. Similarity:\",\n",
    "                                    info=\"Choose a lower threshold between 0.6 and 1.0.\", \n",
    "                                    visible=False, interactive=True)\n",
    "        with gr.Tab(\"Editing a template for prompt\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    is_edit_template = gr.Radio(choices=[\"On\", \"Off\"], type=\"value\",\n",
    "                                                label=\"Template for prompt:\",\n",
    "                                                info=\"Choose a mode to edit a template for prompt. If this feature is enabled, there will be no continuous conversation.\",\n",
    "                                                value=\"Off\", interactive=True)\n",
    "                with gr.Column(scale=3):\n",
    "                    txt_template = gr.TextArea(label=\"The editing area:\",\n",
    "                                               info=\"Edit to fine-tune a template to be inputted into LLM.\",\n",
    "                                               visible=False)\n",
    "\n",
    "    # attach a component and an event procedure\n",
    "    drp_llm.change(fn=change_dropdown_llm, outputs=[is_edit_template, txt_template])\n",
    "    is_retrieval.change(fn=change_radio_retrieval, inputs=[is_retrieval], outputs=[tab_retriever])\n",
    "    is_apply_cond.change(fn=change_radio_apply_cond, inputs=[is_apply_cond], outputs=[sld_sim, nmb_rec])\n",
    "    is_edit_template.change(fn=change_radio_edit_template, inputs=[is_edit_template, txt_template, drp_llm], outputs=[txt_template])\n",
    "\n",
    "    # placed a chatbox!\n",
    "    cht_bot = gr.ChatInterface(fn=chatbot_response, type=\"messages\",\\\n",
    "                               additional_inputs=[\n",
    "                                   drp_llm,\n",
    "                                   is_conversation,\n",
    "                                   is_retrieval,\n",
    "                                   drp_collection,\n",
    "                                   is_apply_cond,\n",
    "                                   nmb_rec, sld_sim,\n",
    "                                   is_edit_template,\n",
    "                                   txt_template,\n",
    "                               ],\n",
    "                               fill_height=True)\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1cb213-46ed-41c5-b260-8760c65de801",
   "metadata": {},
   "source": [
    "## 4. Wrap up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7a0e4-6aaf-4989-b42b-28ae266ce2fe",
   "metadata": {},
   "source": [
    "以上をもって全てのステップが終了となります。一連のステップを通じてLangChainを用いたRAGの実装を体験することができたと思います。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
